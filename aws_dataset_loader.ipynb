{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c428a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.42.31-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting botocore<1.43.0,>=1.42.31 (from boto3)\n",
      "  Downloading botocore-1.42.31-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3)\n",
      "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/kasc/Projects/MasterIU/Adv NLP and CV/written_assignment/.venv/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.31->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/kasc/Projects/MasterIU/Adv NLP and CV/written_assignment/.venv/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.31->boto3) (2.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/kasc/Projects/MasterIU/Adv NLP and CV/written_assignment/.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.31->boto3) (1.17.0)\n",
      "Downloading boto3-1.42.31-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.42.31-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m554.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.42.31 botocore-1.42.31 jmespath-1.0.1 s3transfer-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3781a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded s3://multiconer/multiconer2023/BN-Bangla/bn_dev.conll -> multiconer2023/BN-Bangla/bn_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/BN-Bangla/bn_test.conll -> multiconer2023/BN-Bangla/bn_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/BN-Bangla/bn_train.conll -> multiconer2023/BN-Bangla/bn_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/DE-German/de_dev.conll -> multiconer2023/DE-German/de_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/DE-German/de_test.conll -> multiconer2023/DE-German/de_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/DE-German/de_train.conll -> multiconer2023/DE-German/de_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/EN-English/en_dev.conll -> multiconer2023/EN-English/en_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/EN-English/en_test.conll -> multiconer2023/EN-English/en_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/EN-English/en_train.conll -> multiconer2023/EN-English/en_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/ES-Spanish/es_dev.conll -> multiconer2023/ES-Spanish/es_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/ES-Spanish/es_test.conll -> multiconer2023/ES-Spanish/es_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/ES-Spanish/es_train.conll -> multiconer2023/ES-Spanish/es_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/FA-Farsi/fa_dev.conll -> multiconer2023/FA-Farsi/fa_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/FA-Farsi/fa_test.conll -> multiconer2023/FA-Farsi/fa_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/FA-Farsi/fa_train.conll -> multiconer2023/FA-Farsi/fa_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/FR-French/fr_dev.conll -> multiconer2023/FR-French/fr_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/FR-French/fr_test.conll -> multiconer2023/FR-French/fr_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/FR-French/fr_train.conll -> multiconer2023/FR-French/fr_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/HI-Hindi/hi_dev.conll -> multiconer2023/HI-Hindi/hi_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/HI-Hindi/hi_test.conll -> multiconer2023/HI-Hindi/hi_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/HI-Hindi/hi_train.conll -> multiconer2023/HI-Hindi/hi_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/IT-Italian/it_dev.conll -> multiconer2023/IT-Italian/it_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/IT-Italian/it_test.conll -> multiconer2023/IT-Italian/it_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/IT-Italian/it_train.conll -> multiconer2023/IT-Italian/it_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/MULTI-Multilingual/multi_dev.conll -> multiconer2023/MULTI-Multilingual/multi_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/MULTI-Multilingual/multi_test.conll -> multiconer2023/MULTI-Multilingual/multi_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/MULTI-Multilingual/multi_train.conll -> multiconer2023/MULTI-Multilingual/multi_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/PT-Portuguese/pt_dev.conll -> multiconer2023/PT-Portuguese/pt_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/PT-Portuguese/pt_test.conll -> multiconer2023/PT-Portuguese/pt_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/PT-Portuguese/pt_train.conll -> multiconer2023/PT-Portuguese/pt_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/SV-Swedish/sv_dev.conll -> multiconer2023/SV-Swedish/sv_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/SV-Swedish/sv_test.conll -> multiconer2023/SV-Swedish/sv_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/SV-Swedish/sv_train.conll -> multiconer2023/SV-Swedish/sv_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/UK-Ukrainian/uk_dev.conll -> multiconer2023/UK-Ukrainian/uk_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/UK-Ukrainian/uk_test.conll -> multiconer2023/UK-Ukrainian/uk_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/UK-Ukrainian/uk_train.conll -> multiconer2023/UK-Ukrainian/uk_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/ZH-Chinese/zh_dev.conll -> multiconer2023/ZH-Chinese/zh_dev.conll\n",
      "Downloaded s3://multiconer/multiconer2023/ZH-Chinese/zh_test.conll -> multiconer2023/ZH-Chinese/zh_test.conll\n",
      "Downloaded s3://multiconer/multiconer2023/ZH-Chinese/zh_train.conll -> multiconer2023/ZH-Chinese/zh_train.conll\n",
      "Downloaded s3://multiconer/multiconer2023/readme.md -> multiconer2023/readme.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "BUCKET = \"multiconer\"\n",
    "PREFIX = \"multiconer2023/\"          # note trailing slash\n",
    "DEST_DIR = \"multiconer2023\"         # local folder\n",
    "\n",
    "def download_prefix(bucket: str, prefix: str, dest_dir: str) -> None:\n",
    "    s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "\n",
    "            # Skip \"directory marker\" keys (rare but possible)\n",
    "            if key.endswith(\"/\"):\n",
    "                continue\n",
    "\n",
    "            rel_path = key[len(prefix):] if key.startswith(prefix) else key\n",
    "            local_path = os.path.join(dest_dir, rel_path)\n",
    "\n",
    "            os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "            # Download\n",
    "            s3.download_file(bucket, key, local_path)\n",
    "            print(f\"Downloaded s3://{bucket}/{key} -> {local_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(DEST_DIR, exist_ok=True)\n",
    "    download_prefix(BUCKET, PREFIX, DEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# --- mappings (use your existing dicts) ---\n",
    "# fine_id2label = {...}\n",
    "# coarse_id2label = {...}\n",
    "\n",
    "TOP_K = 25  # set None for all tags (less compact)\n",
    "\n",
    "def trunc10(s: str) -> str:\n",
    "    return s[:10] if len(s) > 10 else s\n",
    "\n",
    "def topk_df(flat_ids: np.ndarray, id2label: dict, drop_o=True, top_k=25):\n",
    "    c = Counter(flat_ids.tolist())\n",
    "    items = [(k, v) for k, v in c.items() if (k != 0 if drop_o else True)]\n",
    "    items = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "    if top_k is not None:\n",
    "        items = items[:top_k]\n",
    "    df = pd.DataFrame(items, columns=[\"tag_id\", \"count\"])\n",
    "\n",
    "    # label: \"<id>:<name_truncated_to_10>\"\n",
    "    df[\"label\"] = df[\"tag_id\"].map(lambda i: f\"{int(i)}:{trunc10(id2label.get(int(i), str(int(i))))}\")\n",
    "\n",
    "    # Keep descending in file; LaTeX will reverse y for \"largest on top\"\n",
    "    return df\n",
    "\n",
    "flat_fine = np.concatenate(ds_test.ner_tags_index.to_numpy())\n",
    "flat_coarse = np.concatenate(ds_test.coarse_ner_tag_idx.to_numpy())\n",
    "\n",
    "# O vs Entity (assumes O == 0)\n",
    "is_entity = flat_fine > 0\n",
    "c_bool = Counter(is_entity)\n",
    "df_bool = pd.DataFrame({\n",
    "    \"label\": [\"O\", \"Entity\"],\n",
    "    \"count\": [c_bool[False], c_bool[True]],\n",
    "})\n",
    "\n",
    "df_coarse = topk_df(flat_coarse, coarse_id2label, drop_o=True, top_k=TOP_K)\n",
    "df_fine   = topk_df(flat_fine,   fine_id2label,   drop_o=True, top_k=TOP_K)\n",
    "\n",
    "df_bool.to_csv(\"o_vs_entity.csv\", index=False)\n",
    "df_coarse.to_csv(\"coarse_topk.csv\", index=False)\n",
    "df_fine.to_csv(\"fine_topk.csv\", index=False)\n",
    "\n",
    "print(\"Wrote: o_vs_entity.csv, coarse_topk.csv, fine_topk.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
